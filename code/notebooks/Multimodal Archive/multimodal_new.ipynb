{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn import decomposition, linear_model,metrics\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "class_labels = LabelEncoder()\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,StratifiedKFold,KFold,train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix,mean_squared_error,r2_score\n",
    "from sklearn.metrics import auc, RocCurveDisplay, roc_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "## Additional imports from DWI code\n",
    "import math\n",
    "from itertools import product\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "from scipy import io, stats\n",
    "#from astropy.stats import jackknife_resampling, jackknife_stats, binom_conf_interval\n",
    "#import xgboost as xgb\n",
    "\n",
    "seed_value= 42\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0     1.0\n1     0.0\n2     1.0\n3     0.0\n4     1.0\n5     1.0\n6     0.0\n7     1.0\n8     1.0\n9     0.0\n10    0.0\n11    0.0\n12    1.0\n13    1.0\n14    0.0\n15    1.0\n16    1.0\n17    0.0\n18    0.0\nName: Late Seizure Label, dtype: float64\nfMRI Subject IDs\n0     3_13_0063\n1     3_13_0068\n2     3_16_0013\n3     3_16_0016\n4     3_16_0023\n5     3_16_0033\n6     3_16_0036\n7     3_17_0001\n8     3_17_0004\n9     3_17_0007\n10    3_17_0009\n11    3_17_0012\n12    3_17_0019\n13    3_17_0048\n14    3_19_0050\n15    3_21_0040\n16    3_21_0061\n17    3_26_0080\n18    3_26_0092\nName: Subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "processed_data_path=\"../../data/processed\"\n",
    "\n",
    "fMRI_features=pd.read_csv(f\"{processed_data_path}/fMRI/fMRI_features_AAL.csv\",index_col=0)\n",
    "## Please take a look at 'print' below. \n",
    "## It either prints 11/14 useable subs with 'Lesion_Overlap_AAL_Subjects_14' \n",
    "## or the 14 useable with a feature length of 19 with 'Lesion_Overlap_AAL_Subjects'.\n",
    "## Currently set to the former of the aforementioned choices.\n",
    "print('fMRI Subject IDs')\n",
    "print(fMRI_features[\"Subject\"])\n",
    "\n",
    "# Here are the fMRI features \n",
    "#pos stands for positive strength\n",
    "#neg stands for negative strength\n",
    "#over stands for lesion overlap\n",
    "# AAL and SCH are the two atlases, so x_pos_aal and x_pos_sch are the same quantity calculated on a slightly different network\n",
    "# All features are in Subjects by Num Sub-features (166 for AAL,100 for SCH)\n",
    "y=labels[label_ind,1]\n",
    "x_pos_aal=pos_str_aal[:,aal_ind].transpose()\n",
    "x_neg_aal=neg_str_aal[:,aal_ind].transpose()\n",
    "x_over_aal=lesion_overlap_aal[:,aal_ind].transpose()\n",
    "x_pos_sch=pos_str_sch[:,aal_ind].transpose()\n",
    "x_neg_sch=neg_str_sch[:,aal_ind].transpose()\n",
    "x_over_sch=lesion_overlap_sch[:,aal_ind].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load EEG and DWI features and sort out which subjects to use programatically\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline fMRI classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmri_classifier(x,y,n_subs,cv_inner,cv_outer,score_string,feature_string):\n",
    "    ''' Prints performance based on nested CV of kPCA combined with SVC for x and y.\n",
    "    '''    \n",
    "    seed_value= 42\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "        \n",
    "    pipe_svc=Pipeline([(\"scale\",StandardScaler()),(\"pca\",KernelPCA()),(\"svm\",SVC(probability=True))])\n",
    "    param_grid_svc={\"pca__n_components\":[2,3,4,5,6],\"pca__gamma\":[.01,.05,.1],\"pca__kernel\":[\"sigmoid\",\"rbf\"],\n",
    "    \"svm__C\": [1, 10, 100], \"svm__gamma\": [.01, .1]}\n",
    "\n",
    "    search_svc=GridSearchCV(estimator=pipe_svc,scoring=score_string,param_grid=param_grid_svc,cv=cv_inner,refit=True)\n",
    "    \n",
    "#     scores_svc = cross_val_score(search_svc, x, y, scoring=score_string, cv=cv_outer, n_jobs=-1\n",
    "#     print(f\"Mean {scores_svc.mean()} and STD {scores_svc.std()}\")\n",
    "\n",
    "## Below excerpts are added to collect train and test predictions from the fMRI classifier\n",
    "\n",
    "    fold_no = cv_outer\n",
    "    data_type  = np.float32\n",
    "    X_fmri = np.zeros((fold_no, n_subs), dtype = data_type) \n",
    "    f1_scores = []\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=fold_no, shuffle=True, \n",
    "                            random_state=seed_value).split(x, y)\n",
    "\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train_CV = x[train_idx,:]  \n",
    "        Y_train_CV = y[train_idx]   \n",
    "        X_test_CV = x[test_idx,:]   \n",
    "        Y_test_CV = y[test_idx]  \n",
    "        \n",
    "        ## 'model' is cleared here, should there be differnt models desired at each fold\n",
    "        model = None\n",
    "        ## The GridSearchCV selected model is passed here\n",
    "        model = search_svc\n",
    "        model.fit(X_train_CV, Y_train_CV)\n",
    "            \n",
    "    ## Predictions for train and test folds are collected as 'soft' labels\n",
    "          \n",
    "        y_train_pred = model.predict(X_train_CV) \n",
    "        y_test_pred = model.predict(X_test_CV)  \n",
    "        \n",
    "        for n in range(len(y_train_pred)):\n",
    "            X_fmri[j,n] = y_train_pred[n]\n",
    "        for q in range(len(y_test_pred)):\n",
    "            X_fmri[j,n+q+1] = y_test_pred[q]\n",
    "                \n",
    "        f1_scores.append(f1_score(Y_test_CV, y_test_pred, average='weighted'))\n",
    "\n",
    "    f1_scores = np.array(f1_scores)\n",
    "    print(feature_string,'\\n',score_string,'Score:')\n",
    "    print(f\"Mean {f1_scores.mean()} and STD {f1_scores.std()}\")\n",
    "    \n",
    "    ## Returns a 'soft' label prediction array, which is [fold_no * no_of_subjects]\n",
    "    return X_fmri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call to the baseline fMRI classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Strength SCH \n",
      " f1 Score:\n",
      "Mean 0.7066666666666667 and STD 0.3968766950969924\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "n_subs = 14 # No. of subjects\n",
    "cv_outer=5\n",
    "cv_inner=KFold(n_splits=3,shuffle=True,random_state=42)\n",
    "\n",
    "# X_fmri = fmri_classifier(x_pos_aal,y,n_subs,cv_inner,cv_outer,\"f1\",\"Positive Strength AAL\")\n",
    "# X_fmri = fmri_classifier(x_neg_aal,y,n_subs,cv_inner,cv_outer,\"f1\",\"Negative Strength AAL\")\n",
    "# X_fmri = fmri_classifier(x_over_aal,y,n_subs,cv_inner,cv_outer,\"f1\",\"Overall Strength AAL\")\n",
    "# X_fmri = fmri_classifier(x_pos_sch,y,n_subs,cv_inner,cv_outer,\"f1\",\"Positive Strength SCH\")\n",
    "X_fmri = fmri_classifier(x_neg_sch,y,n_subs,cv_inner,cv_outer,\"f1\",\"Negative Strength SCH\")\n",
    "# X_fmri = fmri_classifier(x_over_sch,y,n_subs,cv_inner,cv_outer,\"f1\",\"Overall Strength SCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline DWI classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dwi_classifier(X,Y,n_subs,n_feats,cv_outer,score_string,feature_string):\n",
    "    ''' Prints performance based on CV of feature selection combined with LDA for x and y.\n",
    "    '''    \n",
    "    seed_value= 42\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    fold_no = cv_outer\n",
    "    data_type  = np.float32\n",
    "    X_dwi = np.zeros((fold_no, n_subs), dtype = data_type) \n",
    "\n",
    "    f1_scores = []\n",
    "    folds = StratifiedKFold(n_splits=fold_no, shuffle=True, \n",
    "                            random_state=seed_value).split(X, Y)\n",
    "\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train_CV = X.iloc[train_idx,:]  \n",
    "        Y_train_CV = Y.iloc[train_idx]   \n",
    "        Y_train_CV = np.ravel(Y_train_CV)\n",
    "        X_test_CV = X.iloc[test_idx,:]   \n",
    "        Y_test_CV = Y.iloc[test_idx]  \n",
    "        Y_test_CV = np.ravel(Y_test_CV)\n",
    "        \n",
    "        ##--- Univariate feature selection ---##\n",
    "#         sel_mutual = SelectKBest(mutual_info_classif, k=n_feats)\n",
    "        sel_mutual = SelectKBest(chi2, k=n_feats)\n",
    "#         sel_mutual = SelectKBest(f_classif, k=n_feats)\n",
    "\n",
    "        X_train_CV = sel_mutual.fit_transform(X_train_CV, Y_train_CV)\n",
    "        X_test_CV = sel_mutual.transform(X_test_CV)\n",
    "\n",
    "        model = None\n",
    "#         model = LinearDiscriminantAnalysis()      \n",
    "        model = AdaBoostClassifier(n_estimators=100)\n",
    "        model.fit(X_train_CV, Y_train_CV)\n",
    "   \n",
    "        ## Predictions for train folds are collected as 'soft' labels now, \n",
    "        ## Predictions for test folds will not be used in fusion, but storing for reference\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_CV) \n",
    "        y_test_pred = model.predict(X_test_CV)  \n",
    "\n",
    "        for n in range(len(y_train_pred)):\n",
    "            X_dwi[j,n] = y_train_pred[n]\n",
    "        for q in range(len(y_test_pred)):\n",
    "            X_dwi[j,n+q+1] = y_test_pred[q]\n",
    "                \n",
    "        f1_scores.append(f1_score(Y_test_CV, y_test_pred, average='weighted'))\n",
    "\n",
    "    f1_scores = np.array(f1_scores)\n",
    "    print('\\n',feature_string,'Classifier,',score_string,'Score:')\n",
    "    print(f\"Mean {f1_scores.mean()} and STD {f1_scores.std()}\")\n",
    "    \n",
    "    ## Returns a 'soft' label prediction array, which is [fold_no * no_of_subjects]\n",
    "    return X_dwi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call to the baseline DWI classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject IDs (DWI):  \n",
      " 0     3_13_0063_2018-08-16\n",
      "1     3_13_0068_2018-09-25\n",
      "2     3_16_0013_2017-12-14\n",
      "3                3_16_0033\n",
      "4                3_16_0036\n",
      "5     3_17_0001_2017-04-06\n",
      "6                3_17_0004\n",
      "7     3_17_0007_2017-09-08\n",
      "8     3_17_0009_2017-09-18\n",
      "9     3_17_0012_2017-11-18\n",
      "10    3_17_0019_2018-02-15\n",
      "11    3_17_0048_2018-06-10\n",
      "12    3_21_0040_2018-05-05\n",
      "13    3_21_0061_2018-07-18\n",
      "Name: ID, dtype: object\n",
      "\n",
      " chi2-AdaBoost Classifier, f1 Score:\n",
      "Mean 0.9333333333333332 and STD 0.13333333333333336\n"
     ]
    }
   ],
   "source": [
    "dwi_ip = pd.read_csv(\"../../data/processed/DWI/IDs+Labels+Features.csv\")\n",
    "\n",
    "id_subs = dwi_ip.iloc[:, 0]\n",
    "Y = dwi_ip.iloc[:, 1]\n",
    "X = dwi_ip.iloc[:, 2:]\n",
    "\n",
    "print('Subject IDs (DWI): ','\\n',id_subs)\n",
    "\n",
    "n_subs = 14\n",
    "cv_outer = 5\n",
    "n_feats = 7\n",
    "\n",
    "X_dwi = dwi_classifier(X,Y,n_subs,n_feats,cv_outer,\"f1\",\"chi2-AdaBoost\")\n",
    "\n",
    "# n_feats = [i+1 for i in range(10)]\n",
    "# for i in n_feats:\n",
    "#     X_dwi = dwi_classifier(X,Y,n_subs,i,cv_outer,\"f1\",\"chi2-LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline EEG classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def eeg_classifier():\n",
    "##     return X_eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call to the baseline EEG classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X_eeg = eeg_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline fusion classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion classifier \n",
      " F1 Score:\n",
      "Mean 0.9333333333333332 and STD 0.13333333333333336\n"
     ]
    }
   ],
   "source": [
    "seed_value= 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "n_modalities = 2 # No. of modalities for fusion \n",
    "cv_outer = 5\n",
    "n_subs = 14\n",
    "data_type  = np.float32   \n",
    "f1_scores = []\n",
    "X_fusion = np.zeros((cv_outer,n_subs,n_modalities), dtype = data_type) \n",
    "\n",
    "## Meta labels are loaded\n",
    "X_fusion[:,:,0] = X_fmri\n",
    "X_fusion[:,:,1] = X_dwi\n",
    "# X_fusion[:,:,2] = X_eeg\n",
    "\n",
    "## Due to small size of each fold, \n",
    "## certain evaluation metrics and plots are currently omitted\n",
    "\n",
    "folds = StratifiedKFold(n_splits=cv_outer, shuffle=True, \n",
    "                        random_state=seed_value).split(X,Y) \n",
    "\n",
    "for j, (train_idx, test_idx) in enumerate(folds):\n",
    "    X_train_CV = X_fusion[j,0:len(train_idx),:]\n",
    "    Y_train_CV = Y.iloc[train_idx]   \n",
    "    Y_train_CV = np.ravel(Y_train_CV)\n",
    "    X_test_CV = X_fusion[j,len(train_idx):,:]   \n",
    "    Y_test_CV = Y.iloc[test_idx]     \n",
    "    Y_test_CV = np.ravel(Y_test_CV)\n",
    "\n",
    "    model_1 = LogisticRegression(random_state=seed_value)   \n",
    "#     model_2 = GaussianNB()         \n",
    "#     model_3 = make_pipeline(StandardScaler(), SVC(gamma='auto',probability=True))\n",
    "#     model_4 = AdaBoostClassifier(n_estimators=100)\n",
    "#     model_fuse = VotingClassifier(estimators=[('lr',model_1),('gnb',model_2),\n",
    "#                                               ('svc',model_3),('adb',model_4)],voting='soft')\n",
    "\n",
    "    model_1.fit(X_train_CV, Y_train_CV)                      \n",
    "    y_test_pred = model_fuse.predict(X_test_CV)                  \n",
    "    f1_scores.append(f1_score(Y_test_CV, y_test_pred, average='weighted'))\n",
    "\n",
    "f1_scores = np.array(f1_scores)\n",
    "print('Fusion classifier \\n F1 Score:')\n",
    "print(f\"Mean {f1_scores.mean()} and STD {f1_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0599ece31c4fde4e4e1599195ac9379fe78fed0240411f7d7e69c7ad4d96148a7",
   "display_name": "Python 3.7.9 64-bit ('python3.7': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}